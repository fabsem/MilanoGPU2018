{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "    Jupyter notebook for accessing CUDA\n",
    "    Copyright (C) 2018 Andre.Brodtkorb@ifi.uio.no, changed in October by Andr√© Brodtkorb\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "import pycuda.driver as cuda_driver\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import IPythonMagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For timing\n",
    "from Timer import Timer\n",
    "\n",
    "#For logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from ipytest import run_pytest, clean_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global logger already initialized!\n",
      "Registering context in user workspace\n",
      "Context already registered! Ignoring\n"
     ]
    }
   ],
   "source": [
    "%setup_logging\n",
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "cuModuleLoadDataEx failed: an illegal memory access was encountered - ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-67e8210e1668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     20\u001b[0m \"\"\"\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSourceModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matrixVectorKernel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#matrixVectorKernel(float* c, float* A, float* b, int a_rows, int a_cols)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_from_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_from_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcubin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuModuleLoadDataEx failed: an illegal memory access was encountered - "
     ]
    }
   ],
   "source": [
    "cuda_kernel = \"\"\"\n",
    "__global__ void matrixVectorKernel(float* c, float* A, float* b, int a_rows, int a_cols) {\n",
    "    unsigned int j = blockIdx.x*blockDim.x + threadIdx.x; //more efficient threads aligned horizontally\n",
    "    \n",
    "    //Out of bounds check\n",
    "    if (j > a_rows) {\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    //Compute inner product of row of A with column of B\n",
    "    float sum = 0.0f;\n",
    "    for (int i=0; i<a_cols; ++i) {\n",
    "        unsigned int k = j*a_cols + i;\n",
    "        sum += A[k] * b[i];\n",
    "    }\n",
    "    \n",
    "    //Write to global memory\n",
    "    c[j] = sum;\n",
    "}\n",
    "\"\"\"\n",
    "module = cuda_compiler.SourceModule(cuda_kernel)\n",
    "kernel = module.get_function(\"matrixVectorKernel\");\n",
    "#matrixVectorKernel(float* c, float* A, float* b, int a_rows, int a_cols)\n",
    "#The arguments are Pointer,Pointer,Pointer, Int,Int\n",
    "kernel.prepare(\"PPPii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpuMatrixVector(a, b):\n",
    "    #Create an operation of the GPU\n",
    "    stream = cuda_driver.Stream()\n",
    "    #context.synchronize()\n",
    "    \n",
    "    #Upload data to the device\n",
    "    #NOTE: We need to make sure that a=(a_rows, a_columns)\n",
    "    # and that b=(a_colmuns, 1) (column vector)\n",
    "    # and that c=(a_rows, 1)\n",
    "    with Timer(\"Data allocation\") as t:\n",
    "        a_g = GPUArray(a.shape, np.float32)\n",
    "        b_g = GPUArray(b.shape, np.float32)\n",
    "        #Allocate output data\n",
    "        c_g = GPUArray(a.shape[0], np.float32)\n",
    "        context.synchronize()\n",
    "        \n",
    "    with Timer(\"A upload\") as t:\n",
    "        #a_g.set(a)\n",
    "        #context.synchronize()\n",
    "        a_g.set_async(a, stream=stream)\n",
    "        \n",
    "    with Timer(\"B upload\") as t:\n",
    "        #b_g.set(b)\n",
    "        #context.synchronize()\n",
    "        b_g.set_async(b, stram,stream)\n",
    "    \n",
    "    #NOTE: We need to change this so that the grid*block is x = 1, y = number of rows in A\n",
    "    block_size = (32, 1, 1) #These need to be [x, y, z]\n",
    "    grid_size = (int(np.ceil(a.shape[0] / 1)), 1, 1)\n",
    "\n",
    "    print(\"Block size is \" + str(block_size))\n",
    "    print(\"Grid size is \" + str(grid_size))\n",
    "    \n",
    "    #Execute program on device\n",
    "    with Timer(\"Kernel execution\") as t:\n",
    "        #kernel(c_g, a_g, b_g, np.int32(a.shape[0]), np.int32(a.shape[1]), block=block_size, grid=grid_size)\n",
    "        for i in range(100):\n",
    "            kernel.prepared_async_call(grid_size, block_size, stream, \\\n",
    "                                   c_g.gpudata, a_g.gpudata, b_g.gpudata, np.int32(a.shape[0]), np.int32(a.shape[1]), block=block_size, grid=grid_size)\n",
    "        #context.synchronize()\n",
    "        \n",
    "    #Copy data from device to host\n",
    "    with Timer(\"Allocate c\") as t:\n",
    "        c = np.empty((a.shape[0],1), dtype=np.float32)\n",
    "    \n",
    "    #insert timing function\n",
    "    with Timer(\"Download\", logging.INFO) as t:\n",
    "        c_g.get(c)\n",
    "        context.synchronize() #wait to synchronize GPU and CAPU\n",
    "    \n",
    "    #Return our computed matrix-vector product\n",
    "    return c #To skip printing of c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200  400  800 1600 3200 6400 8000] [ 200  400  800 1600 3200 6400 8000]\n"
     ]
    }
   ],
   "source": [
    "nx = np.array([200, 400, 800, 1600, 3200, 6400, 8000])\n",
    "ny = nx\n",
    "\n",
    "print(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create test data: 73.431969 ms\n",
      "Run whole function: 0.063896 ms\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "cuStreamCreate failed: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-70d0844ebef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run whole function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpuMatrixVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#times[i] = t.msecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-b03a01f11016>\u001b[0m in \u001b[0;36mgpuMatrixVector\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgpuMatrixVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Create an operation of the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#context.synchronize()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuStreamCreate failed: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "#times = np.empty_like(nx)\n",
    "#for i in range(len(nx)):\n",
    "   # print(\"Nx = \" + str(nx[i]), flush=True)\n",
    "    #Size of our test\n",
    "    \n",
    "    \n",
    "test_size = (2048, 2048)\n",
    "\n",
    "    #Create test input / output data\n",
    "with Timer(\"Create test data\") as t:\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "\n",
    "with Timer('Run whole function', logging.INFO) as t:\n",
    "    c = gpuMatrixVector(a, b)\n",
    "#times[i] = t.msecs\n",
    "    \n",
    "#print(nx*ny)\n",
    "#print(times)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(a)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(b)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(c)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f41ee6748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f41ee6748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "#plt.plot(nx*ny, times, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad = 0.537384033203125000000000000000\n",
      "Per element error: 0.0002623945474624634\n"
     ]
    }
   ],
   "source": [
    "#Compute reference using Numpy\n",
    "c_ref = np.dot(a, b)\n",
    "\n",
    "#Sum of absolute differences\n",
    "sad = np.sum(np.abs(c - c_ref))\n",
    "\n",
    "#Print result\n",
    "# print(\"C   = \", c)\n",
    "# print(\"Ref = \", c_ref)\n",
    "print(\"Sad = %.30f\" % sad)\n",
    "print(\"Per element error: \" + str(sad / test_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts ==============================\n",
      "platform linux -- Python 3.6.6, pytest-3.8.2, py-1.6.0, pluggy-0.7.1 -- /usr/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/ubuntu/jupyter_notebooks/Fabio/MilanoGPU2018/notebooks, inifile:\n",
      "collecting ... collected 1 item\n",
      "\n",
      "MatrixVectorTesting.py::test_gpuMatrixVector <- <ipython-input-16-21c36f96d5a4> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memory copy time: 0.162601 ms\n",
      "Memory copy time: 0.143051 ms\n",
      "Memory copy time: 0.140905 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED [100%]\n",
      "\n",
      "=============================== warnings summary ===============================\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:29: DeprecationWarning: get() between arrays of different shape is deprecated and will be removed in PyCUDA 2017.x\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "===================== 1 passed, 3 warnings in 0.03 seconds =====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tests() #this initializes the pytest framework\n",
    "\n",
    "def test_gpuMatrixVector():\n",
    "    #Let us test a matrix of size 1x1\n",
    "    a = np.ones((1,1), dtype=np.float32)\n",
    "    b = 2*np.ones((1,1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(2.0) #make sure it is approximate otherwise it will fail\n",
    "    \n",
    "    #Test that the inner product works\n",
    "    a = np.ones((1,2), dtype=np.float32)\n",
    "    b = 2*np.ones((2,1), dtype=np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(4.0)\n",
    "    \n",
    "    #Test a general matrix\n",
    "    test_size = (4, 3)\n",
    "    a = np.random.random(test_size).astype(np.float32)\n",
    "    b = np.random.random((test_size[1], 1)).astype(np.float32)\n",
    "    c = gpuMatrixVector(a, b)\n",
    "    assert c == pytest.approx(np.dot(a, b), rel = 1e-3)\n",
    "    \n",
    "run_pytest(filename='MatrixVectorTesting.ipynb', pytest_options=['-vvv']) #vvv: be really really verbose! We need info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
